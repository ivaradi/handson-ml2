{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 – Training Deep Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 09:06:23.993298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-10 09:06:23.993338: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'HeNormal',\n",
       " 'HeUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'LecunNormal',\n",
       " 'LecunUniform',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'truncated_normal',\n",
       " 'variance_scaling',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f70818703d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f70818700a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 09:25:10.178729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-10 09:25:10.178781: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-10 09:25:10.178813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (652dcbe0efc0): /proc/driver/nvidia/version does not exist\n",
      "2022-09-10 09:25:10.179117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7902\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5832 - accuracy: 0.8075 - val_loss: 0.5582 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5553 - accuracy: 0.8156 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5338 - accuracy: 0.8225 - val_loss: 0.5157 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5172 - accuracy: 0.8272 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5040 - accuracy: 0.8288 - val_loss: 0.4895 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4816 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try PReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7186\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8197 - accuracy: 0.7355 - val_loss: 0.7305 - val_accuracy: 0.7632\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6966 - accuracy: 0.7693 - val_loss: 0.6565 - val_accuracy: 0.7878\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6331 - accuracy: 0.7909 - val_loss: 0.6004 - val_accuracy: 0.8046\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5917 - accuracy: 0.8057 - val_loss: 0.5656 - val_accuracy: 0.8180\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5618 - accuracy: 0.8135 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5390 - accuracy: 0.8205 - val_loss: 0.5196 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5213 - accuracy: 0.8257 - val_loss: 0.5114 - val_accuracy: 0.8318\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5070 - accuracy: 0.8288 - val_loss: 0.4917 - val_accuracy: 0.8380\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4945 - accuracy: 0.8315 - val_loss: 0.4827 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f707f792bf0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7f705c517790>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 32s 17ms/step - loss: 1.1380 - accuracy: 0.5682 - val_loss: 1.0168 - val_accuracy: 0.6272\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 28s 16ms/step - loss: 0.8191 - accuracy: 0.7000 - val_loss: 0.6716 - val_accuracy: 0.7558\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 27s 16ms/step - loss: 0.6693 - accuracy: 0.7570 - val_loss: 0.6708 - val_accuracy: 0.7740\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 28s 16ms/step - loss: 0.6012 - accuracy: 0.7830 - val_loss: 0.5365 - val_accuracy: 0.8090\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 28s 16ms/step - loss: 0.5731 - accuracy: 0.7963 - val_loss: 0.5605 - val_accuracy: 0.8062\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 29s 15ms/step - loss: 1.7856 - accuracy: 0.2707 - val_loss: 1.4668 - val_accuracy: 0.3232\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 25s 15ms/step - loss: 1.1974 - accuracy: 0.4874 - val_loss: 0.9485 - val_accuracy: 0.5874\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 25s 15ms/step - loss: 0.9051 - accuracy: 0.6233 - val_loss: 0.8393 - val_accuracy: 0.6594\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 25s 15ms/step - loss: 0.9448 - accuracy: 0.6307 - val_loss: 1.0754 - val_accuracy: 0.5688\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 25s 14ms/step - loss: 0.8601 - accuracy: 0.6664 - val_loss: 1.1754 - val_accuracy: 0.5624\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bn1.updates #deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.8750 - accuracy: 0.7124 - val_loss: 0.5525 - val_accuracy: 0.8224\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5754 - accuracy: 0.8031 - val_loss: 0.4725 - val_accuracy: 0.8474\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5189 - accuracy: 0.8204 - val_loss: 0.4377 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4827 - accuracy: 0.8323 - val_loss: 0.4153 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4565 - accuracy: 0.8407 - val_loss: 0.3997 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4397 - accuracy: 0.8475 - val_loss: 0.3867 - val_accuracy: 0.8692\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4242 - accuracy: 0.8515 - val_loss: 0.3763 - val_accuracy: 0.8708\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4143 - accuracy: 0.8542 - val_loss: 0.3712 - val_accuracy: 0.8736\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4023 - accuracy: 0.8580 - val_loss: 0.3632 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3914 - accuracy: 0.8624 - val_loss: 0.3573 - val_accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0317 - accuracy: 0.6757 - val_loss: 0.6767 - val_accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6790 - accuracy: 0.7793 - val_loss: 0.5566 - val_accuracy: 0.8182\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 0.5007 - val_accuracy: 0.8362\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5447 - accuracy: 0.8191 - val_loss: 0.4666 - val_accuracy: 0.8450\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5109 - accuracy: 0.8280 - val_loss: 0.4434 - val_accuracy: 0.8532\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4899 - accuracy: 0.8337 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4712 - accuracy: 0.8396 - val_loss: 0.4130 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4560 - accuracy: 0.8439 - val_loss: 0.4035 - val_accuracy: 0.8608\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4441 - accuracy: 0.8474 - val_loss: 0.3943 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4333 - accuracy: 0.8504 - val_loss: 0.3875 - val_accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.5926 - accuracy: 0.8103 - val_loss: 0.3892 - val_accuracy: 0.8675\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.3523 - accuracy: 0.8787 - val_loss: 0.3290 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.3170 - accuracy: 0.8895 - val_loss: 0.3013 - val_accuracy: 0.8991\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2973 - accuracy: 0.8974 - val_loss: 0.2896 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2835 - accuracy: 0.9022 - val_loss: 0.2775 - val_accuracy: 0.9066\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2729 - accuracy: 0.9060 - val_loss: 0.2733 - val_accuracy: 0.9063\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2641 - accuracy: 0.9090 - val_loss: 0.2719 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2572 - accuracy: 0.9124 - val_loss: 0.2589 - val_accuracy: 0.9141\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2518 - accuracy: 0.9133 - val_loss: 0.2561 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2469 - accuracy: 0.9151 - val_loss: 0.2542 - val_accuracy: 0.9158\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2422 - accuracy: 0.9175 - val_loss: 0.2497 - val_accuracy: 0.9155\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2382 - accuracy: 0.9187 - val_loss: 0.2510 - val_accuracy: 0.9133\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2350 - accuracy: 0.9198 - val_loss: 0.2444 - val_accuracy: 0.9155\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2315 - accuracy: 0.9212 - val_loss: 0.2413 - val_accuracy: 0.9173\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2287 - accuracy: 0.9211 - val_loss: 0.2446 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2254 - accuracy: 0.9222 - val_loss: 0.2384 - val_accuracy: 0.9193\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2231 - accuracy: 0.9232 - val_loss: 0.2405 - val_accuracy: 0.9173\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2201 - accuracy: 0.9243 - val_loss: 0.2420 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2178 - accuracy: 0.9253 - val_loss: 0.2329 - val_accuracy: 0.9195\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2156 - accuracy: 0.9258 - val_loss: 0.2331 - val_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 42ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 42ms/step - loss: 0.2654 - accuracy: 0.9400 - val_loss: 0.2797 - val_accuracy: 0.9260\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.2557 - accuracy: 0.9400 - val_loss: 0.2701 - val_accuracy: 0.9300\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2463 - accuracy: 0.9400 - val_loss: 0.2614 - val_accuracy: 0.9331\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2377 - accuracy: 0.9400 - val_loss: 0.2532 - val_accuracy: 0.9371\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 43ms/step - loss: 0.2127 - accuracy: 0.9500 - val_loss: 0.2048 - val_accuracy: 0.9635\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1700 - accuracy: 0.9550 - val_loss: 0.1725 - val_accuracy: 0.9716\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.1411 - accuracy: 0.9700 - val_loss: 0.1497 - val_accuracy: 0.9807\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1200 - accuracy: 0.9800 - val_loss: 0.1330 - val_accuracy: 0.9828\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1048 - accuracy: 0.9900 - val_loss: 0.1205 - val_accuracy: 0.9848\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0931 - accuracy: 0.9950 - val_loss: 0.1105 - val_accuracy: 0.9858\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0839 - accuracy: 0.9950 - val_loss: 0.1024 - val_accuracy: 0.9858\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0764 - accuracy: 0.9950 - val_loss: 0.0956 - val_accuracy: 0.9878\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0700 - accuracy: 0.9950 - val_loss: 0.0895 - val_accuracy: 0.9868\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0643 - accuracy: 0.9950 - val_loss: 0.0847 - val_accuracy: 0.9888\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0598 - accuracy: 0.9950 - val_loss: 0.0803 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9878\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9878\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9878\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1408407837152481, 0.9704999923706055]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05644103139638901, 0.9940000176429749]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of 4.9!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.916666666666718"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 97.05) / (100 - 99.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4899 - accuracy: 0.8269 - val_loss: 0.4069 - val_accuracy: 0.8604\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3793 - accuracy: 0.8653 - val_loss: 0.3728 - val_accuracy: 0.8710\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3468 - accuracy: 0.8772 - val_loss: 0.3749 - val_accuracy: 0.8706\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3260 - accuracy: 0.8846 - val_loss: 0.3509 - val_accuracy: 0.8788\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3108 - accuracy: 0.8893 - val_loss: 0.3451 - val_accuracy: 0.8778\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2974 - accuracy: 0.8942 - val_loss: 0.3419 - val_accuracy: 0.8822\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2873 - accuracy: 0.8979 - val_loss: 0.3379 - val_accuracy: 0.8832\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2782 - accuracy: 0.9015 - val_loss: 0.3419 - val_accuracy: 0.8800\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2700 - accuracy: 0.9026 - val_loss: 0.3291 - val_accuracy: 0.8858\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2626 - accuracy: 0.9059 - val_loss: 0.3281 - val_accuracy: 0.8862\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2567 - accuracy: 0.9090 - val_loss: 0.3264 - val_accuracy: 0.8886\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2506 - accuracy: 0.9115 - val_loss: 0.3336 - val_accuracy: 0.8818\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2450 - accuracy: 0.9131 - val_loss: 0.3248 - val_accuracy: 0.8898\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2409 - accuracy: 0.9144 - val_loss: 0.3289 - val_accuracy: 0.8866\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2357 - accuracy: 0.9165 - val_loss: 0.3230 - val_accuracy: 0.8892\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2317 - accuracy: 0.9186 - val_loss: 0.3205 - val_accuracy: 0.8892\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2278 - accuracy: 0.9188 - val_loss: 0.3248 - val_accuracy: 0.8880\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2238 - accuracy: 0.9210 - val_loss: 0.3194 - val_accuracy: 0.8922\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2205 - accuracy: 0.9228 - val_loss: 0.3229 - val_accuracy: 0.8890\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2172 - accuracy: 0.9240 - val_loss: 0.3208 - val_accuracy: 0.8914\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2135 - accuracy: 0.9257 - val_loss: 0.3204 - val_accuracy: 0.8898\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2110 - accuracy: 0.9264 - val_loss: 0.3185 - val_accuracy: 0.8902\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2081 - accuracy: 0.9269 - val_loss: 0.3207 - val_accuracy: 0.8906\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2053 - accuracy: 0.9292 - val_loss: 0.3203 - val_accuracy: 0.8900\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2031 - accuracy: 0.9295 - val_loss: 0.3200 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8445 - accuracy: 0.7531 - val_loss: 0.9387 - val_accuracy: 0.7308 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6882 - accuracy: 0.7902 - val_loss: 0.6551 - val_accuracy: 0.8044 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6064 - accuracy: 0.8122 - val_loss: 0.8304 - val_accuracy: 0.7448 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.5415 - accuracy: 0.8307 - val_loss: 0.5339 - val_accuracy: 0.8344 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4977 - accuracy: 0.8470 - val_loss: 0.4982 - val_accuracy: 0.8580 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4438 - accuracy: 0.8559 - val_loss: 0.4706 - val_accuracy: 0.8664 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4089 - accuracy: 0.8706 - val_loss: 0.5908 - val_accuracy: 0.8584 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3757 - accuracy: 0.8786 - val_loss: 0.4952 - val_accuracy: 0.8420 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3426 - accuracy: 0.8860 - val_loss: 0.4907 - val_accuracy: 0.8614 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3227 - accuracy: 0.8926 - val_loss: 0.5356 - val_accuracy: 0.8750 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2981 - accuracy: 0.9000 - val_loss: 0.4734 - val_accuracy: 0.8704 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2799 - accuracy: 0.9060 - val_loss: 0.4589 - val_accuracy: 0.8748 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2533 - accuracy: 0.9144 - val_loss: 0.4699 - val_accuracy: 0.8830 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2357 - accuracy: 0.9202 - val_loss: 0.4719 - val_accuracy: 0.8796 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2247 - accuracy: 0.9239 - val_loss: 0.4559 - val_accuracy: 0.8858 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2044 - accuracy: 0.9301 - val_loss: 0.4700 - val_accuracy: 0.8898 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1870 - accuracy: 0.9362 - val_loss: 0.5014 - val_accuracy: 0.8818 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1754 - accuracy: 0.9406 - val_loss: 0.4998 - val_accuracy: 0.8882 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1636 - accuracy: 0.9443 - val_loss: 0.5041 - val_accuracy: 0.8904 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1518 - accuracy: 0.9486 - val_loss: 0.4964 - val_accuracy: 0.8906 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1403 - accuracy: 0.9527 - val_loss: 0.5448 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1330 - accuracy: 0.9555 - val_loss: 0.5782 - val_accuracy: 0.8916 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1247 - accuracy: 0.9593 - val_loss: 0.6149 - val_accuracy: 0.8898 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1178 - accuracy: 0.9616 - val_loss: 0.6326 - val_accuracy: 0.8908 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1107 - accuracy: 0.9637 - val_loss: 0.6145 - val_accuracy: 0.8890 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.8175 - accuracy: 0.7641 - val_loss: 0.7419 - val_accuracy: 0.7640 - lr: 0.0089\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.6557 - accuracy: 0.8008 - val_loss: 0.5459 - val_accuracy: 0.8298 - lr: 0.0079\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5805 - accuracy: 0.8214 - val_loss: 0.7011 - val_accuracy: 0.7866 - lr: 0.0071\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5402 - accuracy: 0.8322 - val_loss: 0.5279 - val_accuracy: 0.8380 - lr: 0.0063\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4909 - accuracy: 0.8469 - val_loss: 0.5734 - val_accuracy: 0.8400 - lr: 0.0056\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4538 - accuracy: 0.8582 - val_loss: 0.4642 - val_accuracy: 0.8600 - lr: 0.0050\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3923 - accuracy: 0.8731 - val_loss: 0.4914 - val_accuracy: 0.8702 - lr: 0.0045\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3696 - accuracy: 0.8798 - val_loss: 0.5020 - val_accuracy: 0.8496 - lr: 0.0040\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3422 - accuracy: 0.8865 - val_loss: 0.4714 - val_accuracy: 0.8740 - lr: 0.0035\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3255 - accuracy: 0.8907 - val_loss: 0.4776 - val_accuracy: 0.8790 - lr: 0.0032\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2934 - accuracy: 0.9020 - val_loss: 0.5006 - val_accuracy: 0.8750 - lr: 0.0028\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2756 - accuracy: 0.9068 - val_loss: 0.5025 - val_accuracy: 0.8738 - lr: 0.0025\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2647 - accuracy: 0.9114 - val_loss: 0.4341 - val_accuracy: 0.8876 - lr: 0.0022\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2343 - accuracy: 0.9206 - val_loss: 0.4506 - val_accuracy: 0.8856 - lr: 0.0020\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2232 - accuracy: 0.9246 - val_loss: 0.4631 - val_accuracy: 0.8856 - lr: 0.0018\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2021 - accuracy: 0.9313 - val_loss: 0.4609 - val_accuracy: 0.8906 - lr: 0.0016\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.1901 - accuracy: 0.9356 - val_loss: 0.4836 - val_accuracy: 0.8872 - lr: 0.0014\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1758 - accuracy: 0.9413 - val_loss: 0.4760 - val_accuracy: 0.8860 - lr: 0.0013\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1627 - accuracy: 0.9458 - val_loss: 0.4822 - val_accuracy: 0.8894 - lr: 0.0011\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1517 - accuracy: 0.9487 - val_loss: 0.4862 - val_accuracy: 0.8886 - lr: 9.9967e-04\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1428 - accuracy: 0.9523 - val_loss: 0.5657 - val_accuracy: 0.8910 - lr: 8.9094e-04\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1318 - accuracy: 0.9563 - val_loss: 0.5344 - val_accuracy: 0.8930 - lr: 7.9404e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.5452 - val_accuracy: 0.8882 - lr: 7.0767e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1149 - accuracy: 0.9622 - val_loss: 0.6071 - val_accuracy: 0.8918 - lr: 6.3071e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1073 - accuracy: 0.9650 - val_loss: 0.6360 - val_accuracy: 0.8908 - lr: 5.6211e-04\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr * 0.1**(1 / self.s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8477 - accuracy: 0.7572 - val_loss: 1.2816 - val_accuracy: 0.6548 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.2164 - accuracy: 0.6235 - val_loss: 1.0857 - val_accuracy: 0.6294 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.1199 - accuracy: 0.6033 - val_loss: 1.2368 - val_accuracy: 0.5864 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.1255 - accuracy: 0.5965 - val_loss: 1.2778 - val_accuracy: 0.5440 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 1.1237 - accuracy: 0.5963 - val_loss: 1.0459 - val_accuracy: 0.6450 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9239 - accuracy: 0.6363 - val_loss: 0.8714 - val_accuracy: 0.6548 - lr: 0.0050\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8571 - accuracy: 0.6461 - val_loss: 0.8438 - val_accuracy: 0.6642 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8619 - accuracy: 0.6453 - val_loss: 1.0201 - val_accuracy: 0.6168 - lr: 0.0050\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8327 - accuracy: 0.6516 - val_loss: 0.9941 - val_accuracy: 0.6614 - lr: 0.0050\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8312 - accuracy: 0.6519 - val_loss: 0.9439 - val_accuracy: 0.6652 - lr: 0.0050\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8157 - accuracy: 0.6541 - val_loss: 0.8593 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8222 - accuracy: 0.6540 - val_loss: 0.9569 - val_accuracy: 0.6664 - lr: 0.0050\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8104 - accuracy: 0.6595 - val_loss: 0.9429 - val_accuracy: 0.6582 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8107 - accuracy: 0.6606 - val_loss: 0.9276 - val_accuracy: 0.6490 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.8209 - accuracy: 0.6579 - val_loss: 0.8905 - val_accuracy: 0.6602 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7074 - accuracy: 0.6710 - val_loss: 0.8302 - val_accuracy: 0.6804 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6929 - accuracy: 0.6725 - val_loss: 0.8840 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6954 - accuracy: 0.6764 - val_loss: 0.8637 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6840 - accuracy: 0.6790 - val_loss: 0.8483 - val_accuracy: 0.6852 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6783 - accuracy: 0.6797 - val_loss: 0.8531 - val_accuracy: 0.6738 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6689 - accuracy: 0.6810 - val_loss: 0.8471 - val_accuracy: 0.6742 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6641 - accuracy: 0.6847 - val_loss: 0.8395 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6640 - accuracy: 0.6879 - val_loss: 0.8280 - val_accuracy: 0.6814 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.5313 - accuracy: 0.7601 - val_loss: 0.6964 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4847 - accuracy: 0.7798 - val_loss: 0.6626 - val_accuracy: 0.7684 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5887 - accuracy: 0.8084 - val_loss: 0.4905 - val_accuracy: 0.8516 - lr: 0.0200\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4991 - accuracy: 0.8394 - val_loss: 0.5884 - val_accuracy: 0.8316 - lr: 0.0200\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5108 - accuracy: 0.8417 - val_loss: 0.5288 - val_accuracy: 0.8530 - lr: 0.0200\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5116 - accuracy: 0.8480 - val_loss: 0.5061 - val_accuracy: 0.8502 - lr: 0.0200\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5148 - accuracy: 0.8508 - val_loss: 0.5284 - val_accuracy: 0.8492 - lr: 0.0200\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4919 - accuracy: 0.8563 - val_loss: 0.4983 - val_accuracy: 0.8636 - lr: 0.0200\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2985 - accuracy: 0.8960 - val_loss: 0.3886 - val_accuracy: 0.8746 - lr: 0.0100\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2542 - accuracy: 0.9073 - val_loss: 0.4050 - val_accuracy: 0.8792 - lr: 0.0100\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2293 - accuracy: 0.9144 - val_loss: 0.3828 - val_accuracy: 0.8880 - lr: 0.0100\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2165 - accuracy: 0.9214 - val_loss: 0.4170 - val_accuracy: 0.8838 - lr: 0.0100\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2040 - accuracy: 0.9242 - val_loss: 0.4226 - val_accuracy: 0.8810 - lr: 0.0100\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1975 - accuracy: 0.9263 - val_loss: 0.4953 - val_accuracy: 0.8676 - lr: 0.0100\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 0.4692 - val_accuracy: 0.8844 - lr: 0.0100\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1760 - accuracy: 0.9344 - val_loss: 0.5053 - val_accuracy: 0.8780 - lr: 0.0100\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1182 - accuracy: 0.9537 - val_loss: 0.4293 - val_accuracy: 0.8888 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0997 - accuracy: 0.9609 - val_loss: 0.4529 - val_accuracy: 0.8962 - lr: 0.0050\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0927 - accuracy: 0.9647 - val_loss: 0.4839 - val_accuracy: 0.8924 - lr: 0.0050\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0858 - accuracy: 0.9667 - val_loss: 0.5009 - val_accuracy: 0.8948 - lr: 0.0050\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0796 - accuracy: 0.9699 - val_loss: 0.5074 - val_accuracy: 0.8972 - lr: 0.0050\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0594 - accuracy: 0.9784 - val_loss: 0.5127 - val_accuracy: 0.8966 - lr: 0.0025\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0537 - accuracy: 0.9806 - val_loss: 0.5266 - val_accuracy: 0.8960 - lr: 0.0025\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0503 - accuracy: 0.9821 - val_loss: 0.5414 - val_accuracy: 0.8966 - lr: 0.0025\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0472 - accuracy: 0.9837 - val_loss: 0.5466 - val_accuracy: 0.8938 - lr: 0.0025\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.5653 - val_accuracy: 0.8966 - lr: 0.0025\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.5669 - val_accuracy: 0.8978 - lr: 0.0012\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4893 - accuracy: 0.8276 - val_loss: 0.4094 - val_accuracy: 0.8600\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3819 - accuracy: 0.8650 - val_loss: 0.3741 - val_accuracy: 0.8700\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3487 - accuracy: 0.8766 - val_loss: 0.3735 - val_accuracy: 0.8680\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3264 - accuracy: 0.8839 - val_loss: 0.3496 - val_accuracy: 0.8796\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3104 - accuracy: 0.8897 - val_loss: 0.3433 - val_accuracy: 0.8800\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2958 - accuracy: 0.8953 - val_loss: 0.3416 - val_accuracy: 0.8810\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2854 - accuracy: 0.8985 - val_loss: 0.3355 - val_accuracy: 0.8818\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2760 - accuracy: 0.9019 - val_loss: 0.3367 - val_accuracy: 0.8822\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2677 - accuracy: 0.9055 - val_loss: 0.3266 - val_accuracy: 0.8852\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2607 - accuracy: 0.9068 - val_loss: 0.3242 - val_accuracy: 0.8854\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2551 - accuracy: 0.9087 - val_loss: 0.3252 - val_accuracy: 0.8874\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2496 - accuracy: 0.9128 - val_loss: 0.3300 - val_accuracy: 0.8816\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2449 - accuracy: 0.9139 - val_loss: 0.3219 - val_accuracy: 0.8876\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2415 - accuracy: 0.9149 - val_loss: 0.3221 - val_accuracy: 0.8874\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2375 - accuracy: 0.9169 - val_loss: 0.3207 - val_accuracy: 0.8880\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2343 - accuracy: 0.9180 - val_loss: 0.3185 - val_accuracy: 0.8888\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2317 - accuracy: 0.9188 - val_loss: 0.3197 - val_accuracy: 0.8896\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2291 - accuracy: 0.9201 - val_loss: 0.3169 - val_accuracy: 0.8906\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2269 - accuracy: 0.9207 - val_loss: 0.3198 - val_accuracy: 0.8894\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2250 - accuracy: 0.9216 - val_loss: 0.3170 - val_accuracy: 0.8894\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2229 - accuracy: 0.9222 - val_loss: 0.3180 - val_accuracy: 0.8900\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2216 - accuracy: 0.9225 - val_loss: 0.3164 - val_accuracy: 0.8912\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2201 - accuracy: 0.9230 - val_loss: 0.3171 - val_accuracy: 0.8900\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2188 - accuracy: 0.9240 - val_loss: 0.3167 - val_accuracy: 0.8908\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2179 - accuracy: 0.9242 - val_loss: 0.3166 - val_accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For piecewise constant scheduling, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In the `on_batch_end()` method, `logs[\"loss\"]` used to contain the batch loss, but in TensorFlow 2.2.0 it was replaced with the mean loss (since the start of the epoch). This explains why the graph below is much smoother than in the book (if you are using TF 2.2 or above). It also means that there is a lag between the moment the batch loss starts exploding and the moment the explosion becomes clear in the graph. So you should choose a slightly smaller learning rate than you would have chosen with the \"noisy\" graph. Alternatively, you can tweak the `ExponentialLearningRate` callback above so it computes the batch loss (based on the current mean loss and the previous mean loss):\n",
    "\n",
    "```python\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.prev_loss = 0\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        batch_loss = logs[\"loss\"] * (batch + 1) - self.prev_loss * batch\n",
    "        self.prev_loss = logs[\"loss\"]\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.3857\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.6572 - accuracy: 0.7740 - val_loss: 0.4872 - val_accuracy: 0.8336\n",
      "Epoch 2/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.4581 - accuracy: 0.8395 - val_loss: 0.4275 - val_accuracy: 0.8522\n",
      "Epoch 3/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.4122 - accuracy: 0.8547 - val_loss: 0.4115 - val_accuracy: 0.8582\n",
      "Epoch 4/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.3837 - accuracy: 0.8642 - val_loss: 0.3869 - val_accuracy: 0.8686\n",
      "Epoch 5/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.3639 - accuracy: 0.8717 - val_loss: 0.3764 - val_accuracy: 0.8688\n",
      "Epoch 6/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.3456 - accuracy: 0.8773 - val_loss: 0.3747 - val_accuracy: 0.8708\n",
      "Epoch 7/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.3330 - accuracy: 0.8811 - val_loss: 0.3635 - val_accuracy: 0.8704\n",
      "Epoch 8/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.3184 - accuracy: 0.8861 - val_loss: 0.3949 - val_accuracy: 0.8604\n",
      "Epoch 9/25\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.3065 - accuracy: 0.8891 - val_loss: 0.3484 - val_accuracy: 0.8764\n",
      "Epoch 10/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2945 - accuracy: 0.8924 - val_loss: 0.3403 - val_accuracy: 0.8800\n",
      "Epoch 11/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2839 - accuracy: 0.8964 - val_loss: 0.3452 - val_accuracy: 0.8810\n",
      "Epoch 12/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2709 - accuracy: 0.9025 - val_loss: 0.3657 - val_accuracy: 0.8684\n",
      "Epoch 13/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2537 - accuracy: 0.9082 - val_loss: 0.3349 - val_accuracy: 0.8844\n",
      "Epoch 14/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2406 - accuracy: 0.9135 - val_loss: 0.3461 - val_accuracy: 0.8802\n",
      "Epoch 15/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2280 - accuracy: 0.9184 - val_loss: 0.3258 - val_accuracy: 0.8844\n",
      "Epoch 16/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2160 - accuracy: 0.9231 - val_loss: 0.3293 - val_accuracy: 0.8838\n",
      "Epoch 17/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.2063 - accuracy: 0.9262 - val_loss: 0.3339 - val_accuracy: 0.8868\n",
      "Epoch 18/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1979 - accuracy: 0.9299 - val_loss: 0.3238 - val_accuracy: 0.8902\n",
      "Epoch 19/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1893 - accuracy: 0.9335 - val_loss: 0.3228 - val_accuracy: 0.8906\n",
      "Epoch 20/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1822 - accuracy: 0.9368 - val_loss: 0.3219 - val_accuracy: 0.8920\n",
      "Epoch 21/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1753 - accuracy: 0.9398 - val_loss: 0.3215 - val_accuracy: 0.8908\n",
      "Epoch 22/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1701 - accuracy: 0.9420 - val_loss: 0.3175 - val_accuracy: 0.8944\n",
      "Epoch 23/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1655 - accuracy: 0.9441 - val_loss: 0.3180 - val_accuracy: 0.8938\n",
      "Epoch 24/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1627 - accuracy: 0.9455 - val_loss: 0.3171 - val_accuracy: 0.8938\n",
      "Epoch 25/25\n",
      "430/430 [==============================] - 2s 6ms/step - loss: 0.1610 - accuracy: 0.9462 - val_loss: 0.3164 - val_accuracy: 0.8940\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor of 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 1.5956 - accuracy: 0.8124 - val_loss: 0.7169 - val_accuracy: 0.8340\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.7197 - accuracy: 0.8274 - val_loss: 0.6850 - val_accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 1.6630 - accuracy: 0.8122 - val_loss: 0.7201 - val_accuracy: 0.8308\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7188 - accuracy: 0.8266 - val_loss: 0.6806 - val_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 0.5708 - accuracy: 0.8029 - val_loss: 0.3612 - val_accuracy: 0.8726\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4180 - accuracy: 0.8462 - val_loss: 0.3498 - val_accuracy: 0.8704\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6617 - accuracy: 0.7611 - val_loss: 0.5781 - val_accuracy: 0.8402\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5547 - accuracy: 0.7965 - val_loss: 0.5424 - val_accuracy: 0.8468\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5258 - accuracy: 0.8062 - val_loss: 0.5011 - val_accuracy: 0.8560\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5048 - accuracy: 0.8125 - val_loss: 0.4774 - val_accuracy: 0.8604\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4923 - accuracy: 0.8174 - val_loss: 0.4667 - val_accuracy: 0.8616\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4834 - accuracy: 0.8206 - val_loss: 0.4884 - val_accuracy: 0.8570\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4708 - accuracy: 0.8243 - val_loss: 0.5111 - val_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4643 - accuracy: 0.8289 - val_loss: 0.4539 - val_accuracy: 0.8632\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4606 - accuracy: 0.8302 - val_loss: 0.4308 - val_accuracy: 0.8762\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4517 - accuracy: 0.8311 - val_loss: 0.4442 - val_accuracy: 0.8630\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4474 - accuracy: 0.8344 - val_loss: 0.4022 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4425 - accuracy: 0.8349 - val_loss: 0.5345 - val_accuracy: 0.8540\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4419 - accuracy: 0.8361 - val_loss: 0.4196 - val_accuracy: 0.8756\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4385 - accuracy: 0.8377 - val_loss: 0.4546 - val_accuracy: 0.8644\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4330 - accuracy: 0.8395 - val_loss: 0.4492 - val_accuracy: 0.8664\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4303 - accuracy: 0.8407 - val_loss: 0.4167 - val_accuracy: 0.8758\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4300 - accuracy: 0.8407 - val_loss: 0.5281 - val_accuracy: 0.8622\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4275 - accuracy: 0.8402 - val_loss: 0.4563 - val_accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4239 - accuracy: 0.8432 - val_loss: 0.4854 - val_accuracy: 0.8690\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4186 - accuracy: 0.8423 - val_loss: 0.4075 - val_accuracy: 0.8764\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.8632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46164268255233765, 0.8632000088691711]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3373 - accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3372928500175476, 0.8854363560676575]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4201 - accuracy: 0.8425\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.55, 0.  , 0.32]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.63, 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.32, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.25, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.31, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.68, 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.8 , 0.  , 0.12, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.5 , 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.08, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.01, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.22, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.44, 0.  , 0.35]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.57, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.01, 0.  , 0.31]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.33, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.09, 0.  , 0.41]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.73, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.72, 0.  , 0.12]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.22, 0.  , 0.42]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.29, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.46, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.43, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.55, 0.  , 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.19, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.85, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.78, 0.  , 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.17, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.61, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.5 , 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.84, 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.42, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.06, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.28, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.64, 0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.14, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.32, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.48, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.38, 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.19, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.88, 0.  , 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.9 , 0.  , 0.09]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.49, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.22, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.76, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.62, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.05, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.97, 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.22, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.34, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.69, 0.  , 0.26]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.43, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.15, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.51, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.66, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.74, 0.  , 0.15]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.07, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.41, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.29, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.97, 0.  , 0.  , 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.07, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.41, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.11, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.7 , 0.  , 0.15]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.2 , 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.27, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.61, 0.  , 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.51, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.06, 0.03, 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.59, 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.9 , 0.  , 0.01, 0.  , 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.17, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.03, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.56, 0.  , 0.42]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.07, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.56, 0.  , 0.21, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.64, 0.  , 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.55, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.55, 0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.48]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.34, 0.  , 0.54]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.27, 0.  , 0.3 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " mc_alpha_dropout (MCAlphaDr  (None, 784)              0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " mc_alpha_dropout_1 (MCAlpha  (None, 300)              0         \n",
      " Dropout)                                                        \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " mc_alpha_dropout_2 (MCAlpha  (None, 100)              0         \n",
      " Dropout)                                                        \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.34, 0.  , 0.55]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4749 - accuracy: 0.8328 - val_loss: 0.3757 - val_accuracy: 0.8636\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.3532 - accuracy: 0.8713 - val_loss: 0.3744 - val_accuracy: 0.8694\n"
     ]
    }
   ],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own solutions to the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = \"elu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train_full, y_train_full), (X_test_full, y_test_full)) = cifar10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = X_train_full[:5000]/255.0\n",
    "X_train = X_train_full[5000:]/255.0\n",
    "y_valid = y_train_full[:5000]\n",
    "y_train = y_train_full[5000:]\n",
    "X_test = X_test_full / 255.00\n",
    "y_test = y_test_full\n",
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate = 5e-5)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 19s 11ms/step - loss: 1.9227 - accuracy: 0.3027 - val_loss: 1.7983 - val_accuracy: 0.3476\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.7135 - accuracy: 0.3828 - val_loss: 1.7149 - val_accuracy: 0.3658\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6279 - accuracy: 0.4134 - val_loss: 1.6667 - val_accuracy: 0.3838\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5706 - accuracy: 0.4336 - val_loss: 1.6457 - val_accuracy: 0.4172\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5266 - accuracy: 0.4515 - val_loss: 1.5640 - val_accuracy: 0.4320\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4919 - accuracy: 0.4661 - val_loss: 1.5337 - val_accuracy: 0.4424\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4597 - accuracy: 0.4761 - val_loss: 1.5310 - val_accuracy: 0.4450\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4314 - accuracy: 0.4881 - val_loss: 1.4907 - val_accuracy: 0.4662\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4089 - accuracy: 0.4955 - val_loss: 1.4936 - val_accuracy: 0.4620\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3862 - accuracy: 0.5036 - val_loss: 1.5030 - val_accuracy: 0.4592\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3687 - accuracy: 0.5098 - val_loss: 1.4878 - val_accuracy: 0.4642\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3478 - accuracy: 0.5172 - val_loss: 1.4742 - val_accuracy: 0.4740\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3292 - accuracy: 0.5231 - val_loss: 1.4682 - val_accuracy: 0.4742\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3128 - accuracy: 0.5306 - val_loss: 1.4260 - val_accuracy: 0.4966\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2958 - accuracy: 0.5368 - val_loss: 1.4556 - val_accuracy: 0.4770\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2798 - accuracy: 0.5442 - val_loss: 1.4453 - val_accuracy: 0.4910\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2643 - accuracy: 0.5481 - val_loss: 1.4430 - val_accuracy: 0.4922\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2481 - accuracy: 0.5518 - val_loss: 1.4367 - val_accuracy: 0.4966\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2345 - accuracy: 0.5574 - val_loss: 1.4379 - val_accuracy: 0.4880\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2199 - accuracy: 0.5639 - val_loss: 1.4401 - val_accuracy: 0.4880\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2117 - accuracy: 0.5632 - val_loss: 1.4781 - val_accuracy: 0.4836\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1940 - accuracy: 0.5726 - val_loss: 1.4247 - val_accuracy: 0.4988\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1796 - accuracy: 0.5795 - val_loss: 1.4303 - val_accuracy: 0.4924\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1666 - accuracy: 0.5834 - val_loss: 1.4368 - val_accuracy: 0.4946\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1528 - accuracy: 0.5876 - val_loss: 1.4014 - val_accuracy: 0.5126\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1388 - accuracy: 0.5925 - val_loss: 1.4526 - val_accuracy: 0.4956\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1248 - accuracy: 0.5991 - val_loss: 1.4670 - val_accuracy: 0.4942\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1142 - accuracy: 0.6015 - val_loss: 1.4744 - val_accuracy: 0.4908\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1020 - accuracy: 0.6073 - val_loss: 1.4618 - val_accuracy: 0.4970\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0903 - accuracy: 0.6097 - val_loss: 1.4610 - val_accuracy: 0.5040\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0762 - accuracy: 0.6153 - val_loss: 1.4926 - val_accuracy: 0.4952\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0631 - accuracy: 0.6203 - val_loss: 1.4686 - val_accuracy: 0.4982\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0539 - accuracy: 0.6246 - val_loss: 1.5051 - val_accuracy: 0.5026\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0411 - accuracy: 0.6285 - val_loss: 1.4888 - val_accuracy: 0.5002\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0276 - accuracy: 0.6326 - val_loss: 1.4902 - val_accuracy: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f705f3d1300>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4217 - accuracy: 0.5051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4217473268508911, 0.5051000118255615]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model1.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model1.add(keras.layers.Dense(100, kernel_initializer = \"he_normal\", use_bias = False))\n",
    "    model1.add(keras.layers.BatchNormalization())\n",
    "    model1.add(keras.layers.Activation(\"elu\"))\n",
    "model1.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer1 = keras.optimizers.Nadam(learning_rate = 5e-4)\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer1, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 32s 17ms/step - loss: 1.8311 - accuracy: 0.3447 - val_loss: 1.6483 - val_accuracy: 0.4114\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.6646 - accuracy: 0.4081 - val_loss: 1.5931 - val_accuracy: 0.4244\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.5949 - accuracy: 0.4365 - val_loss: 1.5264 - val_accuracy: 0.4544\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.5477 - accuracy: 0.4493 - val_loss: 1.5167 - val_accuracy: 0.4622\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.5069 - accuracy: 0.4661 - val_loss: 1.4426 - val_accuracy: 0.4936\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4684 - accuracy: 0.4809 - val_loss: 1.4420 - val_accuracy: 0.4964\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4338 - accuracy: 0.4914 - val_loss: 1.4172 - val_accuracy: 0.4988\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.4033 - accuracy: 0.5050 - val_loss: 1.3932 - val_accuracy: 0.5074\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.3863 - accuracy: 0.5108 - val_loss: 1.3665 - val_accuracy: 0.5142\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.3615 - accuracy: 0.5188 - val_loss: 1.3551 - val_accuracy: 0.5226\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.3411 - accuracy: 0.5252 - val_loss: 1.3639 - val_accuracy: 0.5212\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3175 - accuracy: 0.5341 - val_loss: 1.4061 - val_accuracy: 0.4926\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2969 - accuracy: 0.5432 - val_loss: 1.3817 - val_accuracy: 0.5106\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2840 - accuracy: 0.5448 - val_loss: 1.3480 - val_accuracy: 0.5300\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2628 - accuracy: 0.5533 - val_loss: 1.3810 - val_accuracy: 0.5176\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2528 - accuracy: 0.5558 - val_loss: 1.3447 - val_accuracy: 0.5300\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2359 - accuracy: 0.5622 - val_loss: 1.3217 - val_accuracy: 0.5328\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.2165 - accuracy: 0.5719 - val_loss: 1.3448 - val_accuracy: 0.5314\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2039 - accuracy: 0.5773 - val_loss: 1.3484 - val_accuracy: 0.5288\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1883 - accuracy: 0.5836 - val_loss: 1.3967 - val_accuracy: 0.5098\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 25s 17ms/step - loss: 1.1782 - accuracy: 0.5835 - val_loss: 1.3579 - val_accuracy: 0.5230\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1589 - accuracy: 0.5931 - val_loss: 1.3501 - val_accuracy: 0.5260\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1483 - accuracy: 0.5964 - val_loss: 1.3507 - val_accuracy: 0.5346\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1373 - accuracy: 0.6007 - val_loss: 1.3337 - val_accuracy: 0.5416\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1260 - accuracy: 0.6025 - val_loss: 1.3531 - val_accuracy: 0.5394\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1137 - accuracy: 0.6076 - val_loss: 1.3737 - val_accuracy: 0.5254\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.1038 - accuracy: 0.6120 - val_loss: 1.3585 - val_accuracy: 0.5340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7075cdc250>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model1.fit(X_train, y_train, epochs = 100,\n",
    "           validation_data=(X_valid, y_valid),\n",
    "           callbacks=[early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3301 - accuracy: 0.5261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3300594091415405, 0.5260999798774719]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model2.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model2.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer2 = keras.optimizers.Nadam(learning_rate = 7e-4)\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer1, metrics=[\"accuracy\"])\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means)/X_std\n",
    "X_valid_scaled = (X_valid - X_means)/X_std\n",
    "X_test_scaled = (X_test - X_means)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 18s 11ms/step - loss: 1.9268 - accuracy: 0.2916 - val_loss: 1.7607 - val_accuracy: 0.3478\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6767 - accuracy: 0.3952 - val_loss: 1.6413 - val_accuracy: 0.3946\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5629 - accuracy: 0.4404 - val_loss: 1.5789 - val_accuracy: 0.4290\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4931 - accuracy: 0.4640 - val_loss: 1.5658 - val_accuracy: 0.4486\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4312 - accuracy: 0.4904 - val_loss: 1.5343 - val_accuracy: 0.4576\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3782 - accuracy: 0.5131 - val_loss: 1.4901 - val_accuracy: 0.4744\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3350 - accuracy: 0.5285 - val_loss: 1.5266 - val_accuracy: 0.4694\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2954 - accuracy: 0.5435 - val_loss: 1.4802 - val_accuracy: 0.4904\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2549 - accuracy: 0.5601 - val_loss: 1.4925 - val_accuracy: 0.4736\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2192 - accuracy: 0.5734 - val_loss: 1.4836 - val_accuracy: 0.4898\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1898 - accuracy: 0.5860 - val_loss: 1.5392 - val_accuracy: 0.4858\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1521 - accuracy: 0.5975 - val_loss: 1.5131 - val_accuracy: 0.4846\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1191 - accuracy: 0.6068 - val_loss: 1.5135 - val_accuracy: 0.4944\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0970 - accuracy: 0.6207 - val_loss: 1.4995 - val_accuracy: 0.5060\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0658 - accuracy: 0.6322 - val_loss: 1.5445 - val_accuracy: 0.4960\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5638 - accuracy: 0.5676 - val_loss: 1.5304 - val_accuracy: 0.4810\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1385 - accuracy: 0.6029 - val_loss: 1.5354 - val_accuracy: 0.4890\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0835 - accuracy: 0.6229 - val_loss: 1.5259 - val_accuracy: 0.5024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7074d2e080>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model2.fit(X_train_scaled, y_train, epochs = 100,\n",
    "           validation_data=(X_valid_scaled, y_valid),\n",
    "           callbacks=[early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4636 - accuracy: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4635703563690186, 0.4912000000476837]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model3 = keras.models.Sequential()\n",
    "model3.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model3.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model3.add(keras.layers.AlphaDropout(rate = 0.1))\n",
    "model3.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer3 = keras.optimizers.Nadam(learning_rate = 5e-4)\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer3, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 19s 11ms/step - loss: 1.8968 - accuracy: 0.3234 - val_loss: 1.7560 - val_accuracy: 0.3702\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6631 - accuracy: 0.4132 - val_loss: 1.7088 - val_accuracy: 0.3906\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5749 - accuracy: 0.4446 - val_loss: 1.6143 - val_accuracy: 0.4350\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5094 - accuracy: 0.4688 - val_loss: 1.5605 - val_accuracy: 0.4638\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4501 - accuracy: 0.4930 - val_loss: 1.5242 - val_accuracy: 0.4656\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3972 - accuracy: 0.5112 - val_loss: 1.5272 - val_accuracy: 0.4812\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3561 - accuracy: 0.5278 - val_loss: 1.5643 - val_accuracy: 0.4894\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3142 - accuracy: 0.5427 - val_loss: 1.5041 - val_accuracy: 0.5108\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2794 - accuracy: 0.5566 - val_loss: 1.5282 - val_accuracy: 0.4826\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2472 - accuracy: 0.5706 - val_loss: 1.5141 - val_accuracy: 0.4876\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2166 - accuracy: 0.5794 - val_loss: 1.5147 - val_accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1848 - accuracy: 0.5926 - val_loss: 1.5191 - val_accuracy: 0.5052\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1527 - accuracy: 0.6054 - val_loss: 1.6059 - val_accuracy: 0.5062\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1330 - accuracy: 0.6120 - val_loss: 1.5782 - val_accuracy: 0.4960\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1065 - accuracy: 0.6207 - val_loss: 1.6009 - val_accuracy: 0.5060\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0803 - accuracy: 0.6306 - val_loss: 1.6478 - val_accuracy: 0.5054\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0563 - accuracy: 0.6394 - val_loss: 1.6170 - val_accuracy: 0.5246\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0355 - accuracy: 0.6458 - val_loss: 1.6823 - val_accuracy: 0.4966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70707bb250>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model3.fit(X_train_scaled, y_train, epochs = 100,\n",
    "           validation_data=(X_valid_scaled, y_valid),\n",
    "           callbacks=[early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5175 - accuracy: 0.4955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5174877643585205, 0.49549999833106995]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " mc_alpha_dropout (MCAlphaDr  (None, 100)              0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training = True)\n",
    "    \n",
    "model4 = keras.models.Sequential(\n",
    "    [MCAlphaDropout(rate=0.1) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "     for layer in model3.layers]\n",
    ")\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.509"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(model4, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deep Learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the output layer to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the callbacks we need and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "E0213 19:12:55.493896 4621630912 program.py:311] TensorBoard could not bind to port 6006, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 6006, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 5ms/step - loss: 9.4191 - accuracy: 0.1388 - val_loss: 2.2328 - val_accuracy: 0.2040\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 2.1097 - accuracy: 0.2317 - val_loss: 2.0485 - val_accuracy: 0.2402\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9667 - accuracy: 0.2844 - val_loss: 1.9681 - val_accuracy: 0.2964\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8740 - accuracy: 0.3149 - val_loss: 1.9178 - val_accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8064 - accuracy: 0.3423 - val_loss: 1.8256 - val_accuracy: 0.3384\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7525 - accuracy: 0.3595 - val_loss: 1.7430 - val_accuracy: 0.3692\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7116 - accuracy: 0.3819 - val_loss: 1.7199 - val_accuracy: 0.3824\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6782 - accuracy: 0.3935 - val_loss: 1.6746 - val_accuracy: 0.3972\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6517 - accuracy: 0.4025 - val_loss: 1.6622 - val_accuracy: 0.4004\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6140 - accuracy: 0.4194 - val_loss: 1.7065 - val_accuracy: 0.3840\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5884 - accuracy: 0.4301 - val_loss: 1.6736 - val_accuracy: 0.3914\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5640 - accuracy: 0.4378 - val_loss: 1.6220 - val_accuracy: 0.4224\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5437 - accuracy: 0.4448 - val_loss: 1.6332 - val_accuracy: 0.4144\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5214 - accuracy: 0.4555 - val_loss: 1.5785 - val_accuracy: 0.4326\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5117 - accuracy: 0.4564 - val_loss: 1.6267 - val_accuracy: 0.4164\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4972 - accuracy: 0.4622 - val_loss: 1.5846 - val_accuracy: 0.4316\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4888 - accuracy: 0.4661 - val_loss: 1.5549 - val_accuracy: 0.4420\n",
      "Epoch 18/100\n",
      "<<24 more lines>>\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3362 - accuracy: 0.5212 - val_loss: 1.6025 - val_accuracy: 0.4500\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3360 - accuracy: 0.5207 - val_loss: 1.5175 - val_accuracy: 0.4602\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3031 - accuracy: 0.5302 - val_loss: 1.5397 - val_accuracy: 0.4572\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3082 - accuracy: 0.5308 - val_loss: 1.4997 - val_accuracy: 0.4776\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2882 - accuracy: 0.5338 - val_loss: 1.5482 - val_accuracy: 0.4620\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2889 - accuracy: 0.5355 - val_loss: 1.5474 - val_accuracy: 0.4604\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2761 - accuracy: 0.5410 - val_loss: 1.5434 - val_accuracy: 0.4658\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2658 - accuracy: 0.5481 - val_loss: 1.5502 - val_accuracy: 0.4706\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2554 - accuracy: 0.5489 - val_loss: 1.5527 - val_accuracy: 0.4624\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2504 - accuracy: 0.5471 - val_loss: 1.5482 - val_accuracy: 0.4602\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2516 - accuracy: 0.5545 - val_loss: 1.5881 - val_accuracy: 0.4574\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2401 - accuracy: 0.5566 - val_loss: 1.5403 - val_accuracy: 0.4670\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2305 - accuracy: 0.5570 - val_loss: 1.5343 - val_accuracy: 0.4790\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2228 - accuracy: 0.5615 - val_loss: 1.5344 - val_accuracy: 0.4708\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2161 - accuracy: 0.5619 - val_loss: 1.5782 - val_accuracy: 0.4526\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2124 - accuracy: 0.5641 - val_loss: 1.5182 - val_accuracy: 0.4794\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1870 - accuracy: 0.5766 - val_loss: 1.5435 - val_accuracy: 0.4650\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1925 - accuracy: 0.5701 - val_loss: 1.5532 - val_accuracy: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb1d8ef8790>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4960 - accuracy: 0.4762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4960416555404663, 0.47620001435279846]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the lowest validation loss gets about 47.6% accuracy on the validation set. It took 27 epochs to reach the lowest validation loss, with roughly 8 seconds per epoch on my laptop (without a GPU). Let's see if we can improve performance using Batch Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is very similar to the code above, with a few changes:\n",
    "\n",
    "* I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.\n",
    "* I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "* I renamed the run directories to run_bn_* and the model file name to my_cifar10_bn_model.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 19s 9ms/step - loss: 1.9765 - accuracy: 0.2968 - val_loss: 1.6602 - val_accuracy: 0.4042\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6787 - accuracy: 0.4056 - val_loss: 1.5887 - val_accuracy: 0.4304\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6097 - accuracy: 0.4274 - val_loss: 1.5781 - val_accuracy: 0.4326\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5574 - accuracy: 0.4486 - val_loss: 1.5064 - val_accuracy: 0.4676\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5075 - accuracy: 0.4642 - val_loss: 1.4412 - val_accuracy: 0.4844\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4664 - accuracy: 0.4787 - val_loss: 1.4179 - val_accuracy: 0.4984\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4334 - accuracy: 0.4932 - val_loss: 1.4277 - val_accuracy: 0.4906\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.4054 - accuracy: 0.5038 - val_loss: 1.3843 - val_accuracy: 0.5130\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3816 - accuracy: 0.5106 - val_loss: 1.3691 - val_accuracy: 0.5108\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3547 - accuracy: 0.5206 - val_loss: 1.3552 - val_accuracy: 0.5226\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3244 - accuracy: 0.5371 - val_loss: 1.3678 - val_accuracy: 0.5142\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3078 - accuracy: 0.5393 - val_loss: 1.3844 - val_accuracy: 0.5080\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2889 - accuracy: 0.5431 - val_loss: 1.3566 - val_accuracy: 0.5164\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2607 - accuracy: 0.5559 - val_loss: 1.3626 - val_accuracy: 0.5248\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2580 - accuracy: 0.5587 - val_loss: 1.3616 - val_accuracy: 0.5276\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2441 - accuracy: 0.5586 - val_loss: 1.3350 - val_accuracy: 0.5286\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2241 - accuracy: 0.5676 - val_loss: 1.3370 - val_accuracy: 0.5408\n",
      "Epoch 18/100\n",
      "<<29 more lines>>\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0336 - accuracy: 0.6369 - val_loss: 1.3682 - val_accuracy: 0.5450\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0228 - accuracy: 0.6388 - val_loss: 1.3348 - val_accuracy: 0.5458\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0205 - accuracy: 0.6407 - val_loss: 1.3490 - val_accuracy: 0.5440\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0008 - accuracy: 0.6489 - val_loss: 1.3568 - val_accuracy: 0.5408\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9785 - accuracy: 0.6543 - val_loss: 1.3628 - val_accuracy: 0.5396\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9832 - accuracy: 0.6592 - val_loss: 1.3617 - val_accuracy: 0.5482\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.9707 - accuracy: 0.6581 - val_loss: 1.3767 - val_accuracy: 0.5446\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9590 - accuracy: 0.6651 - val_loss: 1.4200 - val_accuracy: 0.5314\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9548 - accuracy: 0.6668 - val_loss: 1.3692 - val_accuracy: 0.5450\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9480 - accuracy: 0.6667 - val_loss: 1.3841 - val_accuracy: 0.5310\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9411 - accuracy: 0.6716 - val_loss: 1.4036 - val_accuracy: 0.5382\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9383 - accuracy: 0.6708 - val_loss: 1.4114 - val_accuracy: 0.5236\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9258 - accuracy: 0.6769 - val_loss: 1.4224 - val_accuracy: 0.5324\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9072 - accuracy: 0.6836 - val_loss: 1.3875 - val_accuracy: 0.5442\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8996 - accuracy: 0.6850 - val_loss: 1.4449 - val_accuracy: 0.5280\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9050 - accuracy: 0.6835 - val_loss: 1.4167 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.8934 - accuracy: 0.6880 - val_loss: 1.4260 - val_accuracy: 0.5294\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.3344 - accuracy: 0.5398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3343921899795532, 0.5397999882698059]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Is the model converging faster than before?* Much faster! The previous model took 27 epochs to reach the lowest validation loss, while the new model achieved that same loss in just 5 epochs and continued to make progress until the 16th epoch. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
    "* *Does BN produce a better model?* Yes! The final model is also much better, with 54.0% accuracy instead of 47.6%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
    "* *How does BN affect training speed?* Although the model converged much faster, each epoch took about 12s instead of 8s, because of the extra computations required by the BN layers. But overall the training time (wall time) was shortened significantly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 10s 5ms/step - loss: 2.0622 - accuracy: 0.2631 - val_loss: 1.7878 - val_accuracy: 0.3552\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7328 - accuracy: 0.3830 - val_loss: 1.7028 - val_accuracy: 0.3828\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6342 - accuracy: 0.4279 - val_loss: 1.6692 - val_accuracy: 0.4022\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5524 - accuracy: 0.4538 - val_loss: 1.6350 - val_accuracy: 0.4300\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4979 - accuracy: 0.4756 - val_loss: 1.5773 - val_accuracy: 0.4356\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4428 - accuracy: 0.4902 - val_loss: 1.5529 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3966 - accuracy: 0.5126 - val_loss: 1.5290 - val_accuracy: 0.4682\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3549 - accuracy: 0.5232 - val_loss: 1.4633 - val_accuracy: 0.4792\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3162 - accuracy: 0.5444 - val_loss: 1.4787 - val_accuracy: 0.4776\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2825 - accuracy: 0.5534 - val_loss: 1.4794 - val_accuracy: 0.4934\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2529 - accuracy: 0.5682 - val_loss: 1.5529 - val_accuracy: 0.4982\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2256 - accuracy: 0.5784 - val_loss: 1.4942 - val_accuracy: 0.4902\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2049 - accuracy: 0.5823 - val_loss: 1.4868 - val_accuracy: 0.5024\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1627 - accuracy: 0.6012 - val_loss: 1.4839 - val_accuracy: 0.5082\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1543 - accuracy: 0.6034 - val_loss: 1.5097 - val_accuracy: 0.4968\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1200 - accuracy: 0.6135 - val_loss: 1.5001 - val_accuracy: 0.5120\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1028 - accuracy: 0.6199 - val_loss: 1.4856 - val_accuracy: 0.5056\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0863 - accuracy: 0.6265 - val_loss: 1.5116 - val_accuracy: 0.4966\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0715 - accuracy: 0.6345 - val_loss: 1.5787 - val_accuracy: 0.5070\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0342 - accuracy: 0.6453 - val_loss: 1.4987 - val_accuracy: 0.5144\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0169 - accuracy: 0.6531 - val_loss: 1.6292 - val_accuracy: 0.4462\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1346 - accuracy: 0.6074 - val_loss: 1.5280 - val_accuracy: 0.5136\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9820 - accuracy: 0.6678 - val_loss: 1.5392 - val_accuracy: 0.5040\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9701 - accuracy: 0.6679 - val_loss: 1.5505 - val_accuracy: 0.5170\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3604 - accuracy: 0.6753 - val_loss: 1.5468 - val_accuracy: 0.4992\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0177 - accuracy: 0.6510 - val_loss: 1.5474 - val_accuracy: 0.5020\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9425 - accuracy: 0.6798 - val_loss: 1.5545 - val_accuracy: 0.5076\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9005 - accuracy: 0.6902 - val_loss: 1.5659 - val_accuracy: 0.5138\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4633 - accuracy: 0.4792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4633383750915527, 0.47920000553131104]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4633 - accuracy: 0.4792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4633383750915527, 0.47920000553131104]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 47.9% accuracy, which is not much better than the original model (47.6%), and not as good as the model using batch normalization (54.0%). However, convergence was almost as fast as with the BN model, plus each epoch took only 7 seconds. So it's by far the fastest model to train so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 5ms/step - loss: 2.0583 - accuracy: 0.2742 - val_loss: 1.7429 - val_accuracy: 0.3858\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.6852 - accuracy: 0.4008 - val_loss: 1.7055 - val_accuracy: 0.3792\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5963 - accuracy: 0.4413 - val_loss: 1.7401 - val_accuracy: 0.4072\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5231 - accuracy: 0.4634 - val_loss: 1.5728 - val_accuracy: 0.4584\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4619 - accuracy: 0.4887 - val_loss: 1.5448 - val_accuracy: 0.4702\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.4074 - accuracy: 0.5061 - val_loss: 1.5678 - val_accuracy: 0.4664\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.3718 - accuracy: 0.5222 - val_loss: 1.5764 - val_accuracy: 0.4824\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3220 - accuracy: 0.5387 - val_loss: 1.4805 - val_accuracy: 0.4890\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2908 - accuracy: 0.5487 - val_loss: 1.5521 - val_accuracy: 0.4638\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2537 - accuracy: 0.5607 - val_loss: 1.5281 - val_accuracy: 0.4924\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.2215 - accuracy: 0.5782 - val_loss: 1.5147 - val_accuracy: 0.5046\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1910 - accuracy: 0.5831 - val_loss: 1.5248 - val_accuracy: 0.5002\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1659 - accuracy: 0.5982 - val_loss: 1.5620 - val_accuracy: 0.5066\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1282 - accuracy: 0.6120 - val_loss: 1.5440 - val_accuracy: 0.5180\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.1127 - accuracy: 0.6133 - val_loss: 1.5782 - val_accuracy: 0.5146\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0917 - accuracy: 0.6266 - val_loss: 1.6182 - val_accuracy: 0.5182\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.0620 - accuracy: 0.6331 - val_loss: 1.6285 - val_accuracy: 0.5126\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0433 - accuracy: 0.6413 - val_loss: 1.6299 - val_accuracy: 0.5158\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0087 - accuracy: 0.6549 - val_loss: 1.7172 - val_accuracy: 0.5062\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.9950 - accuracy: 0.6571 - val_loss: 1.6524 - val_accuracy: 0.5098\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9848 - accuracy: 0.6652 - val_loss: 1.7686 - val_accuracy: 0.5038\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9597 - accuracy: 0.6744 - val_loss: 1.6177 - val_accuracy: 0.5084\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9399 - accuracy: 0.6790 - val_loss: 1.7095 - val_accuracy: 0.5082\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9148 - accuracy: 0.6884 - val_loss: 1.7160 - val_accuracy: 0.5150\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.9023 - accuracy: 0.6949 - val_loss: 1.7017 - val_accuracy: 0.5152\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8732 - accuracy: 0.7031 - val_loss: 1.7274 - val_accuracy: 0.5088\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.8542 - accuracy: 0.7091 - val_loss: 1.7648 - val_accuracy: 0.5166\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8499 - accuracy: 0.7118 - val_loss: 1.7973 - val_accuracy: 0.5000\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4805 - accuracy: 0.4890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4804893732070923, 0.48899999260902405]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model reaches 48.9% accuracy on the validation set. That's very slightly better than without dropout (47.6%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions for all the instances in the validation set, and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4892"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get no accuracy improvement in this case (we're still at 48.9% accuracy).\n",
    "\n",
    "So the best model we got in this exercise is the Batch Normalization model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.1255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.999999747378752e-06,\n",
       " 9.999868392944336,\n",
       " 2.6167492866516113,\n",
       " 3.9354368618556435)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 3s 6ms/step - loss: 2.2298 - accuracy: 0.2349 - val_loss: 1.7841 - val_accuracy: 0.3834\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.7928 - accuracy: 0.3689 - val_loss: 1.6806 - val_accuracy: 0.4086\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.6475 - accuracy: 0.4190 - val_loss: 1.6378 - val_accuracy: 0.4350\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.5428 - accuracy: 0.4543 - val_loss: 1.6266 - val_accuracy: 0.4390\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.4865 - accuracy: 0.4769 - val_loss: 1.6158 - val_accuracy: 0.4384\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.4339 - accuracy: 0.4866 - val_loss: 1.5850 - val_accuracy: 0.4412\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.4042 - accuracy: 0.5056 - val_loss: 1.6146 - val_accuracy: 0.4384\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.3437 - accuracy: 0.5229 - val_loss: 1.5299 - val_accuracy: 0.4846\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 1.2721 - accuracy: 0.5459 - val_loss: 1.5145 - val_accuracy: 0.4874\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.1942 - accuracy: 0.5698 - val_loss: 1.4958 - val_accuracy: 0.5040\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.1211 - accuracy: 0.6033 - val_loss: 1.5406 - val_accuracy: 0.4984\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.0673 - accuracy: 0.6161 - val_loss: 1.5284 - val_accuracy: 0.5144\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.9927 - accuracy: 0.6435 - val_loss: 1.5449 - val_accuracy: 0.5140\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.9205 - accuracy: 0.6703 - val_loss: 1.5652 - val_accuracy: 0.5224\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8936 - accuracy: 0.6801 - val_loss: 1.5912 - val_accuracy: 0.5198\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 47.6% to 52.0%). The batch normalized model reaches a slightly better performance (54%), but it's much slower to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
